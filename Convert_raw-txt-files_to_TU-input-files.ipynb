{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6ea7f7-b379-4fc7-9681-fc84b86daed1",
   "metadata": {},
   "source": [
    "# Description\n",
    "This notebook loads a bunch of txt-files including data about \n",
    "1. TIME     \n",
    "2. FASTF     \n",
    "3. PCOOL      \n",
    "4. TCOOL      \n",
    "5. GKL        \n",
    "6. PITCH      \n",
    "7. [Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q10] \n",
    "\n",
    "These variables are stored in a dataset list where each element is a numpy array that contains the relevant values evaluated at some macro time-steps. \\\n",
    "The purporse of this notebook is to convert the numpy arrays to string-input files that can be handled by the TU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1adbc9-8967-4527-b034-5e22aa9eab21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os, re\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from numba import njit\n",
    "from time import perf_counter as pc\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# plt.style.use([\"notebook\", \"science\"])\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 7]\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "\n",
    "np.set_printoptions(linewidth=200)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a45617-51fd-4f0c-9701-1fc43aec4964",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bde2d7f-810f-4560-8f0e-0b9146a06362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6186/6186 [00:02<00:00, 2310.39it/s]\n"
     ]
    }
   ],
   "source": [
    "map_path = \"raw txt-input 6186 samples 10 nodes/\"\n",
    "\n",
    "dir_list = os.listdir(map_path) # all the files\n",
    "paths = [file for file in dir_list if file.endswith(\".txt\")] # filtering out files which is not txt\n",
    "# a list with arrays \n",
    "dataset = [np.loadtxt(map_path + path) for path in tqdm(paths)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3caba6-d2fa-467f-a96d-dd7789c0dc8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following functions tries to convert the numpy arrays in the dataset list to input-files that can be handled by the TU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f0458287-a872-47c7-af9f-3d61404912a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.47610   0.62180   0.98600   0.23220   0.64340\n",
      "   0.93130   0.47700   0.44940   0.94660   0.46480\n"
     ]
    }
   ],
   "source": [
    "def get_features(data): # add pressure later\n",
    "    t = data[...,0]\n",
    "    Q = data[...,6:] \n",
    "    P = data[...,2:3].mean() # this is alsmost always constant\n",
    "    FASTF = data[...,1:2]\n",
    "    T = data[...,3:4].flatten()\n",
    "    \n",
    "    return t, Q, P, FASTF, T\n",
    "\n",
    "\n",
    "def int_to_list(integer): # parameter must be between 0 and 999\n",
    "    \"\"\"\n",
    "    int_to_list(123) -> [1,2,3]\n",
    "    int_to_list(3) -> [0,0,3]\n",
    "    \"\"\"\n",
    "    result = [int(s) for s in str(integer)]  \n",
    "    if integer > 99:\n",
    "        return result\n",
    "    if integer > 9:\n",
    "        return [0] + result \n",
    "    else:\n",
    "        return [0,0,integer]\n",
    "\n",
    "    \n",
    "def header(*args, message=\"begin\"):\n",
    "    \"\"\"\n",
    "    header(1,2) -> \"* data point #12 begin\"\n",
    "    header(0,0,3) -> \"* data point #003 begin\"\n",
    "    header(1,3,4,5) -> \"* data point #1345 begin\"\n",
    "    \n",
    "    Should be used together with \"int_to_list\"\n",
    "    header(*int_to_list(10), message=\"begin\") -> \"* data point #010 begin\"\n",
    "    \"\"\"\n",
    "    n_dict = len(args) * \"{}\"\n",
    "    result = \"* data point #\" + n_dict + f\" {message}\"\n",
    "    return result.format(*args)\n",
    "\n",
    "\n",
    "@np.vectorize\n",
    "def convert_E_to_D(number): \n",
    "    \"\"\"\n",
    "    Converts a number/array to another array with fortran compatible format as an array where the element is a string.\n",
    "    \n",
    "    convert_E_to_D(123) -> array('1.2300000000000D+02', dtype='<U19')\n",
    "    convert_E_to_D([123, 456.7]) -> array(['1.2300000000000D+02', '4.5670000000000D+02'], dtype='<U19')\n",
    "    \n",
    "    To get a string representation just wrap str around the result.\n",
    "    \n",
    "    str(convert_E_to_D([123, 456.7])) -> \"['1.2300000000000D+02' '4.5670000000000D+02']\"\n",
    "    \"\"\"\n",
    "    scientific_format = format(float(number), \"0.13E\")\n",
    "    fortran_format = str(scientific_format).replace(\"E\", \"D\") # replacing the E of the scientific notation to a D\n",
    "    return fortran_format\n",
    "\n",
    "\n",
    "def string_with_floats_to_array(sequence_str):\n",
    "    \"\"\"\n",
    "    string_with_floats_to_array(\"1 2 3\") -> array([1, 2, 3])\n",
    "    \"\"\"\n",
    "    sequence = np.array([float(s) for s in sequence_str.split(\" \") if s != \"\"]) \n",
    "    return sequence\n",
    "\n",
    "\n",
    "def increase_spacing_opt(text, spacing=3, significant_digits=5):\n",
    "    \"\"\"\n",
    "    text: string with floats separated by space with absolute value smaller than 1\n",
    "    spacing: int\n",
    "    significant_digits: integer larger or equal to 1\n",
    "    \n",
    "    Takes a string of space separated numbers and icrease the spacing between the numbers.\n",
    "    Also padds the right side with zeros to make sure that all the numbers have the same number of characters.\n",
    "    \n",
    "    increase_spacing(\"0.1 0.24    0.369\", spacing=3, significant_digits=5) -> \"   0.10000   0.24000   0.36900\"\n",
    "    \"\"\"\n",
    "    lines = text.split(\"\\n\") # Split string by newline\n",
    "    floats = [[float(x) for x in line.split()] for line in lines] # convert substrings to floats\n",
    "\n",
    "    # Use a nested list comprehension to format the floats with a width of 9, and include trailing spaces\n",
    "    string_format = \"{:\" + f\"{significant_digits + 2 * spacing - 1}.{significant_digits}\" + \"f}\"\n",
    "    formatted_floats = [[string_format.format(x) for x in sublist] for sublist in floats]\n",
    "    formatted_floats = [\"\".join(sublist) for sublist in formatted_floats] # Join the sublists\n",
    "    final_string = \"\\n\".join(formatted_floats) # Join the sublists with newline\n",
    "    \n",
    "    return final_string\n",
    "\n",
    "\n",
    "\n",
    "@np.vectorize\n",
    "def array_formatter(text, precision=5, fractional=True, unique=False):\n",
    "    \"\"\"\n",
    "    Mapping a list with elements with inconsistent number of decimals\n",
    "    to an array where every element is represented as a string \n",
    "    with \"precision\" number of significant digits.\n",
    "    \n",
    "    array_formatter([0.123456, 0.654321467]) -> array(['0.12346', '0.65432'], dtype='<U7')\n",
    "    \"\"\"\n",
    "    return np.format_float_positional(text, precision=precision, unique=unique, fractional=fractional)\n",
    "\n",
    "\n",
    "def split_array(array, split_sizes, axis=-1):\n",
    "    # Validate that the total split size equals the size of the specified axis\n",
    "    if np.sum(split_sizes) != array.shape[axis]:\n",
    "        raise ValueError('Total split sizes must equal the size of the specified axis')\n",
    "        \n",
    "    split_indices = np.cumsum(split_sizes)[:-1]\n",
    "    split_arrays = np.split(array, split_indices, axis)\n",
    "    return split_arrays\n",
    "\n",
    "\n",
    "def array_to_table(profiles):\n",
    "    \"\"\"\n",
    "    Turns an array of profiles to a list of rows representated as strings.\n",
    "    This is a high level function taht should be used with array_formatter and increase_spacing.\n",
    "    \n",
    "    array_to_table([[0.1,0.2], [0.3,0.4]]) -> ['   0.10000   0.20000', '   0.30000   0.40000']\n",
    "    \"\"\"\n",
    "    profiles = np.array(profiles)\n",
    "    profile_chuncks = np.ceil(profiles.shape[-1] / 8).astype(int) # integer, usually have a value of 4\n",
    "    partitions = np.array_split(profiles[None], profile_chuncks, axis=-1) # list of arrays\n",
    "    partitions = np.concatenate(partitions, axis=0) \n",
    "#    partitions = split_array(profiles, [8, 2])\n",
    "\n",
    "    table = np.swapaxes(partitions, 0, 1) \n",
    "    table_str = array_formatter(table)\n",
    "    table_float = table_str.astype(np.float64)\n",
    "    table_float_mod = np.array2string(table_float).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    table_modified = increase_spacing_opt(table_float_mod)\n",
    "    # table_mod but split up into chuncks\n",
    "    table_modified_chuncks = table_modified.split(\"\\n\\n\")\n",
    "    \n",
    "    return table_modified_chuncks\n",
    "\n",
    "def save_to_TU(string, n, map_dir):\n",
    "    with open(map_dir + \"\\TU_\" + f\"{n}.txt\", \"w\") as file:\n",
    "        file.write(string)\n",
    "    file.close()\n",
    "    \n",
    "separation_line = \"*---+----+-------------------+-------------------+---------+---------------------\\n\"\n",
    "\n",
    "def print_time(t, complete_file):\n",
    "    # for visual purporses\n",
    "    complete_file += separation_line + \"*   1: printout of the result at time [hours]\\n\" + separation_line\n",
    "    complete_file += t + \"\\n\"\n",
    "    complete_file += separation_line\n",
    "    return complete_file\n",
    "\n",
    "\n",
    "def program_termination(t, complete_file):\n",
    "    complete_file += \"*  00:  last line of data set (finishing the program)\\n\"\n",
    "    complete_file += separation_line + \"00000    0\" + t + \"\\n\"\n",
    "    complete_file += separation_line\n",
    "    return complete_file\n",
    "\n",
    "profiles = np.random.rand(33, 10)\n",
    "profile_chuncks = np.ceil(profiles.shape[-1] / 8).astype(int) # integer, usually have a value of 4\n",
    "partitions = np.array_split(profiles[None], profile_chuncks, axis=-1) # list of arrays\n",
    "partitions = np.concatenate(partitions, axis=0) \n",
    "\n",
    "print(array_to_table(profiles)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2d8bc-076f-4643-b97f-1f51ead32c58",
   "metadata": {
    "tags": []
   },
   "source": [
    "The numbers 2, 3, 9, 10 in the following printout\\\n",
    "*---+----+-------------------+-------------------+---------+---------------------\\\n",
    "    2    1 0.0000000000000D+00 2.1240100000000D+01\\\n",
    "   0.59300   0.86800   1.01500   1.11400   1.18000\\\n",
    "   1.21500   1.21000   1.16000   1.01900   0.62400\\\n",
    "    3    1 0.0000000000000D+00 1.0284456420000D+13\\\n",
    "   0.59300   0.86800   1.01500   1.11400   1.18000\\\n",
    "   1.21500   1.21000   1.16000   1.01900   0.62400\\\n",
    "    9    0 0.0000000000000D+00 2.9170000000000D+02\\\n",
    "   10    0 0.0000000000000D+00 1.5800000000000D+01\\\n",
    "*---+----+-------------------+-------------------+---------+---------------------\\\n",
    "has the following corresponding meaning\\\n",
    "2: LHGR \\\n",
    "3: Flux \\\n",
    "9: Temperature \\\n",
    "10: Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "634ac58c-cc13-49ca-ad21-3236fb0621a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 10)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-5ca41bf9ccdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#for n in tqdm(range(len(dataset))): # len(dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mph_to_TU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-5ca41bf9ccdb>\u001b[0m in \u001b[0;36mph_to_TU\u001b[0;34m(data, n, save)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# printing out the time (visual purporse)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcomplete_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_attribute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mcomplete_file\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mheat_headline\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mQ_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                        \u001b[0;34m+\u001b[0m \u001b[0mflux_headline\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflux_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                        \u001b[0;34m+\u001b[0m \u001b[0mtemperature_headline\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def ph_to_TU(data, n, save=True):\n",
    "    t, Q, P, FASTF, T = get_features(data)\n",
    "\n",
    "    Q_mean = Q.mean(-1, keepdims=True)\n",
    "    Q_profiles = Q / Q_mean\n",
    "    \n",
    "    flux = Q * FASTF / 10 # n/(cm^2 s)\n",
    "    flux_mean = flux.mean(-1, keepdims=True)\n",
    "    flux_profiles = Q_profiles * FASTF / FASTF.mean(1, keepdims=True)\n",
    "\n",
    "    complete_file = \"\"\n",
    "\n",
    "    # doing a vectorized operation before the loop to save some time\n",
    "    t_fortran = convert_E_to_D(t)\n",
    "    Q_mean_fortran = convert_E_to_D(Q_mean[:,0])\n",
    "    flux_mean_fortran = convert_E_to_D(flux_mean[:,0])\n",
    "\n",
    "    Q_table = array_to_table(Q_profiles)\n",
    "    flux_table = array_to_table(flux_profiles)\n",
    "\n",
    "    # adding the staring line\n",
    "    complete_file += header(*int_to_list(n+1), message=\"begin\") + \"\\n*\\n\"\n",
    "\n",
    "    for i in range(len(t)):\n",
    "        heat_headline = \"{:5d}{:5d} {} {}\\n\".format(2, 1, t_fortran[i], Q_mean_fortran[i])\n",
    "        flux_headline = \"{:5d}{:5d} {} {}\\n\".format(3, 1, t_fortran[i], flux_mean_fortran[i])\n",
    "        temperature_headline = \"{:5d}{:5d} {} {}\\n\".format(9, 0, t_fortran[i], convert_E_to_D(T[i]))\n",
    "        pressure_headline = \"{:5d}{:5d} {} {}\\n\".format(10, 0, t_fortran[i], convert_E_to_D(P.mean()))\n",
    "        time_attribute = \"{:5d}{:5d} {}\".format(1, 0, t_fortran[i])\n",
    "        \n",
    "        # printing out the time (visual purporse)\n",
    "        complete_file = print_time(time_attribute, complete_file)\n",
    "        complete_file += heat_headline + Q_table[i] + \"\\n\" \\\n",
    "                       + flux_headline + flux_table[i] + \"\\n\" \\\n",
    "                       + temperature_headline \\\n",
    "                       + pressure_headline\n",
    "    \n",
    "\n",
    "    complete_file += header(*int_to_list(n+1), message=\"end\") + \"\\n\"\n",
    "    complete_file = program_termination(f\" {t_fortran[i]}\", complete_file)\n",
    "\n",
    "    print(complete_file)\n",
    "    \n",
    "    if save:\n",
    "        save_to_TU(complete_file, n, map_dir=\"input/dataset 12491/subset 6186\") # specify which map\n",
    "            \n",
    "            \n",
    "#for n in tqdm(range(len(dataset))): # len(dataset)\n",
    "for n in [0]:\n",
    "    ph_to_TU(dataset[n], n, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c057c2-2da5-47e3-9ea9-7ac08f502703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3340e5b-24a3-4884-b940-96c8f88cb6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca8d07-b222-4aa1-9b48-673ebb6e9c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
