{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23597f39-cda8-4b5e-8799-62c354579759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# !pip install SciencePlots -q\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scienceplots\n",
    "from itertools import product\n",
    "import numpy as np \n",
    "import os, re\n",
    "from tqdm.notebook import tqdm\n",
    "from numba import njit\n",
    "from scipy.interpolate import interp1d\n",
    "from math import ceil \n",
    "from time import perf_counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def max_scaling(x):\n",
    "    x_max = x.max()\n",
    "    return x / x_max\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch import zeros, tensor, Tensor, rand\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    print(\"Using\", n_gpus, \"GPUs\")\n",
    "    device = \"cuda\"\n",
    "\n",
    "elif torch.cuda.device_count() == 1:\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    print(\"Using\", n_gpus, \"GPU\")    \n",
    "    device = \"cuda\"\n",
    "\n",
    "else:\n",
    "    n_gpus = 0\n",
    "    print(\"Using CPU\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "\n",
    "plt.style.use([\"notebook\", \"science\"])\n",
    "plt.style.use([\"notebook\", \"nature\"])\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "\n",
    "np.set_printoptions(linewidth=200)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626359ff-eabb-490f-9493-ca0fce8d0808",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98cd3e52-72a9-4e6b-b217-7f567d386be7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = rand(1000, 80, 11)\n",
    "y = rand(1000, 80, 48)\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, x, c, y):\n",
    "        self.dropout = 0.0\n",
    "        self.batch_size, self.sequence_length, self.dynamic_size = x.shape\n",
    "        self.static_size = c.shape[-1] # number of static variables\n",
    "        self.hidden_size = 20          # size of the hidden state, influences the number of parameters\n",
    "        self.output_size = x.shape[-1] # number of predicted outputs\n",
    "        self.n_head = 1\n",
    "        self.n_quantiles = 1\n",
    "        self.modes  = 16 \n",
    "        \n",
    "\n",
    "c = rand(X.shape[0], 2)\n",
    "config = Config(X, c, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b472a1-f0d2-4f53-a8ef-1accee7021e8",
   "metadata": {},
   "source": [
    "# VSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b13bd7-2515-445d-a30d-cd738221001a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "class MaybeLayerNorm(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, eps):\n",
    "        super().__init__()\n",
    "        if output_size and output_size == 1:\n",
    "            self.ln = nn.Identity()\n",
    "        else:\n",
    "            self.ln = LayerNorm(output_size if output_size else hidden_size, eps=eps)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.ln(x)\n",
    "    \n",
    "    \n",
    "# Works like a more advanced matrix multiplication.\n",
    "# Note how the output dimension of the linear layer is doubled, \n",
    "# this is because the gating mechanism splits the tensor along the last dimension \n",
    "# and produces a \"gate\" which may be used to filter out less important features\n",
    "class GLU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(input_size, hidden_size * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = F.glu(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class GRN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 output_size=None,\n",
    "                 context_hidden_size=None,\n",
    "                 dropout=0.0,):\n",
    "        super().__init__()\n",
    "        self.layer_norm = MaybeLayerNorm(output_size, hidden_size, eps=1e-3)\n",
    "        self.lin_a = nn.Linear(input_size, hidden_size)\n",
    "        if context_hidden_size is not None:\n",
    "            self.lin_c = nn.Linear(context_hidden_size, hidden_size, bias=False)\n",
    "        else:\n",
    "            self.lin_c = nn.Identity()\n",
    "        self.lin_i = nn.Linear(hidden_size, hidden_size)\n",
    "        self.glu = GLU(hidden_size, output_size if output_size else hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_proj = nn.Linear(input_size, output_size) if output_size else None\n",
    "\n",
    "    def forward(self, a, c = None):\n",
    "        x = self.lin_a(a)\n",
    "        if c is not None:\n",
    "            x = x + self.lin_c(c).unsqueeze(1)\n",
    "        x = F.elu(x)\n",
    "        x = self.lin_i(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.glu(x)\n",
    "        y = a if self.out_proj is None else self.out_proj(a)\n",
    "        x = x + y\n",
    "        return self.layer_norm(x) \n",
    "\n",
    "    \n",
    "    \n",
    "class VariableSelectionNetwork(nn.Module):\n",
    "    def __init__(self, config): #dynamic_size, static_size, output_size, sequence_length\n",
    "        super().__init__()\n",
    "        self.projection_layer = GLU(config.dynamic_size, config.output_size)\n",
    "        self.static_layer     = GLU(config.static_size, config.output_size) if config.static_size >= 1 else nn.Identity() \n",
    "        self.dynamic_matrix   = nn.Parameter(rand(1, sequence_length, output_size))\n",
    "        self.alpha            = nn.Parameter(tensor(0.0))\n",
    "            \n",
    "    def forward(self, x, c):\n",
    "        self.static_importance_weights  = self.static_layer(c).softmax(-1) # static normalized weights \n",
    "        self.dynamic_importance_weights = torch.einsum( # dynamic normalized weights\n",
    "            \"bto, bti -> bo\", \n",
    "            self.dynamic_matrix, x\n",
    "        ).softmax(-1) \n",
    "        \n",
    "        # Weighted sum\n",
    "        self.variable_importance_weights = \\\n",
    "        self.alpha.sigmoid() * self.static_importance_weights + \\\n",
    "        (1 - self.alpha.sigmoid()) * self.dynamic_importance_weights\n",
    "        \n",
    "        x = self.projection_layer(x)\n",
    "        weighted_results = self.variable_importance_weights.unsqueeze(1) * x\n",
    "        \n",
    "        return weighted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6fb80-1f84-4fb3-8ba0-22fb8dfd228a",
   "metadata": {},
   "source": [
    "# IMHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4f5e7f7-bf5e-41c6-ae2f-f68a0a4aab82",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InterpretableMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_head = config.n_head\n",
    "        assert self.hidden_size % config.n_head == 0\n",
    "        self.d_head = self.hidden_size // self.n_head\n",
    "        self.qkv_linears = nn.Linear(input_size, (2 * self.n_head + 1) * self.d_head, bias=False)\n",
    "\n",
    "        self.out_proj = nn.Linear(self.hidden_size, output_size, bias=False)\n",
    "        self.out_dropout = nn.Dropout(config.dropout)\n",
    "        self.scale = self.d_head**-0.5\n",
    "        self.mask = torch.triu(torch.full(2*[config.sequence_length], float(\"-inf\")), diagonal=1)[None] # causal attention mask that can be broadcasted batch wise\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, t, h_size = x.shape\n",
    "        \n",
    "        qkv = self.qkv_linears(x)\n",
    "    \n",
    "        q, k, v = qkv.split(self.n_head * self.d_head, dim=-1)\n",
    "        q = q.view(bs, t, self.n_head, self.d_head)\n",
    "        k = k.view(bs, t, self.n_head, self.d_head)\n",
    "        v = v.view(bs, t, self.d_head)\n",
    "\n",
    "        attn_score = torch.einsum(\"bind, bjnd -> bnij\", q, k) # computing the attention score\n",
    "        attn_score *= self.scale # normalization\n",
    "        attn_score += self.mask # causal mask\n",
    "\n",
    "        attn_prob = F.softmax(attn_score, dim=-1) # row-wise normalized attention\n",
    "\n",
    "        attn_vec = torch.einsum(\"bnij, bjd -> bnid\", attn_prob, v) # batched matrix multiplication \n",
    "        attn_vec = attn_vec.view(bs, t, self.hidden_size) # reshaping into\n",
    "        \n",
    "        out = self.out_proj(attn_vec)\n",
    "        out = self.out_dropout(out)\n",
    "\n",
    "        return out, attn_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff504bd-3cf2-4915-bd15-0848e3e08da6",
   "metadata": {},
   "source": [
    "# FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99198c7f-220f-41ed-8c37-ec47909a7544",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FNO(nn.Module):\n",
    "    def __init__(self, hidden_size, modes, layers=1, \n",
    "                 input_size=X.shape[-1], \n",
    "                 output_size=y.shape[-1],\n",
    "        ):\n",
    "        super(FNO, self).__init__()\n",
    "\n",
    "        self.modes = min(modes, X.shape[1] // 2 + 1)\n",
    "        self.n_layers = layers\n",
    "        self.activation = F.gelu\n",
    "        \n",
    "        self.input_size  = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.p = nn.Linear(self.input_size, self.hidden_size)\n",
    "        \n",
    "        self.spectral = nn.ModuleList()\n",
    "        self.temporal = nn.ModuleList()\n",
    "        self.residual = nn.ModuleList() \n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            self.spectral += [SpectralConv1d(self.hidden_size, self.hidden_size, self.modes)]\n",
    "            self.temporal += [TemporalConv1d(self.hidden_size, self.hidden_size, self.hidden_size)]\n",
    "            self.residual += [TemporalConv1d(self.hidden_size, self.hidden_size, 1)]\n",
    "        \n",
    "        self.alpha = nn.Parameter(zeros(1))\n",
    "        self.q = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # switched place between permute and p\n",
    "        x = self.p(x)\n",
    "        x = x.permute(0, 2, 1) \n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            x1 = self.spectral[i](x)\n",
    "            x1 = self.temporal[i](x1)\n",
    "            x2 = self.residual[i](x)\n",
    "            \n",
    "            alpha = self.alpha.sigmoid() # 0 - 1: if alpha = 0.5 then it is equivalent to a residual layer\n",
    "            x = 2 * ((1 - alpha) * x1 + alpha * x2)\n",
    "            x = self.activation(x)\n",
    "            \n",
    "        # switched place here aswell\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.q(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes = modes\n",
    "        self.weights = nn.Parameter(\n",
    "            zeros([1, in_channels, out_channels, self.modes], dtype=torch.cfloat)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "        out_ft = torch.zeros(x.shape[0], self.out_channels, x.shape[-1] // 2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        # Batched weighted matrix multiplications\n",
    "        out_ft[...,:self.modes] = torch.einsum(\"bix, biox -> box\", x_ft[...,:self.modes], self.weights)\n",
    "        x = torch.fft.irfft(out_ft, n=x.shape[-1])\n",
    "        return x\n",
    "    \n",
    "\n",
    "class TemporalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels):\n",
    "        super(TemporalConv1d, self).__init__()\n",
    "        \n",
    "        self.activation = F.gelu\n",
    "        \n",
    "        self.input  = nn.Conv1d(in_channels, mid_channels, 1)\n",
    "        self.conv1  = nn.Conv1d(mid_channels, mid_channels, 1)\n",
    "        self.conv2  = nn.Conv1d(mid_channels, mid_channels, 1)\n",
    "        self.output = nn.Conv1d(mid_channels, out_channels, 1)\n",
    "        \n",
    "        self.alpha1 = nn.Parameter(zeros(1))\n",
    "        self.alpha2 = nn.Parameter(zeros(1))\n",
    "        self.alpha3 = nn.Parameter(zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        \n",
    "        x1 = x\n",
    "        x2 = self.conv1(x1)\n",
    "        x2 = self.activation(x2)\n",
    "        x3 = self.conv2(x2)\n",
    "        x3 = self.activation(x3)\n",
    "        \n",
    "        x = self.alpha1.sigmoid() * x1 \\\n",
    "          + self.alpha2.sigmoid() * x2 \\\n",
    "          + self.alpha3.sigmoid() * x3\n",
    "\n",
    "        x = self.output(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b0acb3-6bd6-487d-9b5f-fd6d37a3e9c6",
   "metadata": {},
   "source": [
    "# TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36158537-60d7-47b0-93cd-3c92bcefff2b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module): \n",
    "    \n",
    "    \"\"\"\n",
    "    The padding is performed both to the left AND the right of the actual sequence. \n",
    "    However, we only need the left padding to preserve the time causal relationship.\n",
    "    To resolve this, we need to cut the convolved sequence that is double padded.\n",
    "    This is done for the last dimension as the dimension of the input tensor is transposed.\n",
    "    The size of the cut is determined by the size of the padding.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x[..., :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalConvBlock(nn.Module):\n",
    "    def __init__(self, input_channels, kernel_size, dilation, padding, layers_per_block, weight_init=\"default\"):\n",
    "        super(TemporalConvBlock, self).__init__()\n",
    "        \n",
    "        self.layers_per_block = layers_per_block\n",
    "        self.activation = nn.LeakyReLU(0.01) \n",
    "        self.conv = nn.ModuleList()\n",
    "        self.chomp = nn.ModuleList()\n",
    "        self.alpha = nn.Parameter(zeros(1))\n",
    "        \n",
    "        # Weight initialization \n",
    "        if weight_init == 'default':\n",
    "            conv_weight_init = lambda w: w\n",
    "        elif weight_init == \"kaiming\" or weight_init == \"he\":\n",
    "            conv_weight_init = lambda w: nn.init.kaiming_normal_(w, nonlinearity='relu')\n",
    "        elif weight_init == 'xavier':\n",
    "            conv_weight_init = lambda w: nn.init.xavier_normal_(w, gain=nn.init.calculate_gain('relu'))\n",
    "        else:\n",
    "            raise ValueError('Invalid weight initialization method')\n",
    "\n",
    "        for i in range(self.layers_per_block):\n",
    "            conv_layer = nn.Conv1d(input_channels, input_channels, kernel_size, padding=padding, dilation=dilation)\n",
    "            conv_weight_init(conv_layer.weight)\n",
    "            self.conv  += [weight_norm(conv_layer)]\n",
    "            self.chomp += [Chomp1d(padding)]\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i in range(self.layers_per_block):\n",
    "            x1 = x\n",
    "            x2 = self.conv[i](x1)\n",
    "            x2 = self.chomp[i](x2)\n",
    "            x2 = self.activation(x2)\n",
    "            alpha = self.alpha.sigmoid() # 0 to 1, 1 gievs more weight to identity map\n",
    "            x = 2 * (alpha * x1 + (1 - alpha) * x2) # x1=identity map, x2=everything\n",
    "        return x\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, hidden_size, layers_per_block=2, dilation_base=2, kernel_size=3, \n",
    "                 input_size=X.shape[-1],\n",
    "                 output_size=y.shape[-1],\n",
    "                 weight_init=\"default\",\n",
    "        ):\n",
    "        super(TCN, self).__init__()\n",
    "        \n",
    "\n",
    "        self.sequence_length = X.shape[1]\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dilation_base = dilation_base\n",
    "        self.number_of_layers = np.ceil(\n",
    "            np.log((self.sequence_length - 1) * (self.dilation_base - 1) / (kernel_size - 1) + 1) \n",
    "            / np.log(self.dilation_base)\n",
    "        ).astype(int)\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(self.number_of_layers):\n",
    "            dilation_size = self.dilation_base ** i # this is a generalized dilation rate\n",
    "            self.layers += [TemporalConvBlock(self.hidden_size, kernel_size, \n",
    "                                              dilation=dilation_size, \n",
    "                                              layers_per_block=layers_per_block,\n",
    "                                              padding=(kernel_size-1) * dilation_size,\n",
    "                                              weight_init=weight_init,\n",
    "                                             )]\n",
    "            self.layers += [nn.BatchNorm1d(num_features=self.hidden_size)]\n",
    "            \n",
    "        self.network = nn.Sequential(*self.layers)\n",
    "        self.p = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.q = nn.Linear(self.hidden_size, self.output_size)  \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.p(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.network(x) \n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.q(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e617a18d-f293-4d0a-bb4b-9f4a4f70e03d",
   "metadata": {},
   "source": [
    "# TFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da00589e-f43a-4e8e-89a7-bc1eea879676",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TFN(nn.Module):\n",
    "    def __init__(self, hidden_size, modes=np.infty, \n",
    "                 layers=1, n_quantiles=1, \n",
    "                 input_size=X.shape[-1],\n",
    "                 output_size=y.shape[-1],\n",
    "        ):\n",
    "        super(TFN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.modes = min(modes, X.shape[1] // 2 + 1)\n",
    "        self.activation = F.gelu\n",
    "        self.n_quantiles = n_quantiles\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size * self.n_quantiles\n",
    "        \n",
    "        self.FNO = FNO(self.hidden_size, self.modes, layers, input_size=self.input_size, output_size=self.output_size)\n",
    "        self.TCN = TCN(self.hidden_size, 2 ,2, 3, input_size=self.input_size, output_size=self.output_size)\n",
    "        \n",
    "        self.alpha = nn.Parameter(zeros(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        TCN_predictions = self.TCN(x)\n",
    "        FNO_predictions = self.FNO(x)\n",
    "        \n",
    "        alpha = self.alpha.sigmoid() # 0 < alpha < 1, initialized at alpha = 0.5, 0 means that the temporal domain is prefered over the frequency counterpart \n",
    "        TFN_predictions = alpha * FNO_predictions + (1 - alpha) * TCN_predictions\n",
    "        quantile_predictions = TFN_predictions.view(\n",
    "            *x.shape[:-1], self.output_size // self.n_quantiles, self.n_quantiles\n",
    "        ).contiguous()\n",
    "        \n",
    "        return quantile_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f34d965-028c-4c84-a681-b84d4940fcf8",
   "metadata": {},
   "source": [
    "# ITFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "720f65dc-6250-46d7-8f7f-863112763d36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ITFN(nn.Module):\n",
    "    def __init__(self, config, layers=1):\n",
    "        super(ITFN, self).__init__()\n",
    "        \n",
    "        self.TFN  = TFN(config.hidden_size, config.modes, layers)\n",
    "        self.IMHA = InterpretableMultiHeadAttention(config.hidden_size, config.hidden_size, config.output_size, config)\n",
    "        self.VSN  = VariableSelectionNetwork(\n",
    "            config.dynamic_size, \n",
    "            config.static_size, \n",
    "            config.output_size, \n",
    "            config.sequence_length\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, c):\n",
    "        x = self.VSN(x, c)\n",
    "        x = self.TFN(x)\n",
    "        x, self.attn_prob = self.IMHA(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55dae5-fa10-477c-bf48-6fb9fe7bb5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
